{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubberLanding/AdversarialMachineLearning24/blob/nico/adversarial_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWRfFtr2j9T-",
        "outputId": "566179af-76ba-4879-b23a-53e77221266f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "# !pip install git+https://github.com/fra31/auto-attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgFph_IRo8BW",
        "outputId": "d5b6e08f-3c98-4337-b078-204e0f122b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=17fmN8eQdLpq2jIMQ_X0IXDPXfI9oVWgq\n",
            "From (redirected): https://drive.google.com/uc?id=17fmN8eQdLpq2jIMQ_X0IXDPXfI9oVWgq&confirm=t&uuid=ccb31ef0-0748-4558-8175-1e76db1fcb31\n",
            "To: /content/state_dicts.zip\n",
            "100% 979M/979M [00:07<00:00, 125MB/s]\n"
          ]
        }
      ],
      "source": [
        "# \"\"\"Download pre-trained weights for ResNet18 on CIFAR10\"\"\"\n",
        "# !pip install gdown\n",
        "\n",
        "# # Source: https://github.com/huyvnphan/PyTorch_CIFAR10\n",
        "# FILE_ID = \"17fmN8eQdLpq2jIMQ_X0IXDPXfI9oVWgq\"\n",
        "# file_url = f\"https://drive.google.com/uc?id={FILE_ID}\"\n",
        "\n",
        "# !gdown {file_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DIOCbEGHlAu9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX34q7fo-l5R",
        "outputId": "a5f283f1-f19d-4356-c9d2-0c799f18e549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "project_dir = Path('/content/drive/MyDrive/adversarial_training')\n",
        "project_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "weight_dir = project_dir / \"weights\"\n",
        "weight_dir.mkdir(parents=True, exist_ok=True)\n",
        "weight_file = weight_dir / \"resnet18.pt\"\n",
        "\n",
        "# \"\"\"Extract the pre-trained model weights to Google Drive\"\"\"\n",
        "# with zipfile.ZipFile(\"state_dicts.zip\", \"r\") as zip_ref:\n",
        "#   # print(zip_ref.namelist())\n",
        "#   with zip_ref.open(\"state_dicts/resnet18.pt\") as zf, open(weight_file, 'wb') as f:\n",
        "#       shutil.copyfileobj(zf, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bqVEbYQFJS_c"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "def generate_run_name():\n",
        "    \"\"\"Generate a random name for a run.\"\"\"\n",
        "    colors = [\n",
        "        \"red\", \"blue\", \"green\", \"yellow\", \"purple\", \"orange\", \"pink\",\n",
        "        \"black\", \"white\", \"gray\", \"silver\", \"gold\", \"cyan\", \"magenta\"]\n",
        "    adjectives = [\n",
        "        \"fast\", \"slow\", \"shiny\", \"dull\", \"bright\", \"dark\", \"silent\",\n",
        "        \"loud\", \"brave\", \"calm\", \"wise\", \"fierce\", \"kind\", \"strong\"]\n",
        "    nouns = [\n",
        "        \"dragon\", \"tiger\", \"lion\", \"panda\", \"wolf\", \"phoenix\", \"eagle\",\n",
        "        \"fox\", \"bear\", \"shark\", \"hawk\", \"cheetah\", \"whale\", \"octopus\"]\n",
        "    color = random.choice(colors)\n",
        "    adjective = random.choice(adjectives)\n",
        "    noun = random.choice(nouns)\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "    run_name = f\"{color}-{adjective}-{noun}-{timestamp}\"\n",
        "    return run_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLo5cWwgkquv",
        "outputId": "6ff0becc-44fb-4fd1-8403-d808c2b43b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1024 # batch size has to be < 2**16, should be <= 2**13 for T4\n",
        "debug = True\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.491, 0.482, 0.446], std=[0.247, 0.243, 0.261]),\n",
        "    ])\n",
        "\n",
        "\"\"\" Load data \"\"\"\n",
        "data_train = CIFAR10(root=\"datasets\", train=True, download=True, transform=transform)\n",
        "data_test = CIFAR10(root=\"datasets\", train=False, download=True, transform=transform)\n",
        "data_test, data_val = torch.utils.data.random_split(data_test, [0.1, 0.9])\n",
        "\n",
        "num_classes = len(data_train.classes)\n",
        "\n",
        "# mean = data_train.data.mean(axis=(0,1,2)) / 255 # [0.49139968, 0.48215841, 0.44653091]\n",
        "# std = data_train.data.std(axis=(0,1,2)) / 255 # [0.24703223, 0.24348513, 0.26158784]\n",
        "\n",
        "data_train_subset = Subset(data_train, list(range(2*batch_size)))\n",
        "data_test_subset = Subset(data_test, list(range(2*batch_size)))\n",
        "\n",
        "dataloader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
        "dataloader_test = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n",
        "dataloader_val = DataLoader(data_val, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GSHC7WdoyxSC"
      },
      "outputs": [],
      "source": [
        "def fgsm(model, X, y, epsilon=8/255):\n",
        "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
        "    delta = torch.zeros_like(X, requires_grad=True)\n",
        "    loss = CrossEntropyLoss()(model(X + delta), y)\n",
        "    loss.backward()\n",
        "    return epsilon * delta.grad.detach().sign()\n",
        "\n",
        "def pgd_linf(model, X, y, epsilon=16/255, alpha=2/255, num_iter=10, randomize=False):\n",
        "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
        "    if randomize:\n",
        "        delta = torch.rand_like(X, requires_grad=True)\n",
        "        delta.data = delta.data * 2 * epsilon - epsilon\n",
        "    else:\n",
        "        delta = torch.zeros_like(X, requires_grad=True)\n",
        "\n",
        "    for t in range(num_iter):\n",
        "        loss = CrossEntropyLoss()(model(X + delta), y)\n",
        "        loss.backward()\n",
        "        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
        "        delta.grad.zero_()\n",
        "    return delta.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Dxm_8JdYoK3D"
      },
      "outputs": [],
      "source": [
        "def train_epoch(loader, model, opt):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    model.train()\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        yp = model(X)\n",
        "        loss = CrossEntropyLoss()(yp,y)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(loader, model):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        yp = model(X)\n",
        "        loss = CrossEntropyLoss()(yp,y)\n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n",
        "def train_epoch_adversarial(loader, model, attack, opt, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    model.train()\n",
        "    total_loss, total_err = 0.,0.\n",
        "    for X,y in loader:\n",
        "        X,y = X.to(device), y.to(device)\n",
        "        delta = attack(model, X, y, **kwargs)\n",
        "        yp = model(X+delta)\n",
        "        loss = CrossEntropyLoss()(yp,y)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "        total_loss += loss.item() * X.shape[0]\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_epoch_adversarial(loader, model, attack, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss, total_err = 0.0, 0.0\n",
        "\n",
        "    for X, y in loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute adversarial perturbations (requires gradients)\n",
        "        with torch.enable_grad():\n",
        "            delta = attack(model, X, y, **kwargs)\n",
        "\n",
        "        # Evaluate the model on adversarial examples without gradients\n",
        "        with torch.no_grad():\n",
        "            yp = model(X + delta)\n",
        "            loss = torch.nn.CrossEntropyLoss()(yp, y)\n",
        "\n",
        "            total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
        "            total_loss += loss.item() * X.shape[0]\n",
        "\n",
        "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "LyCAOqCdy-Gs",
        "outputId": "496941a1-a425-4703-9567-383fdcd9cd1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin adversarial training run: blue-fast-cheetah-20250105-1442\n",
            "\n",
            "TR      \tTE      \tADV     \t     \n",
            "0.254980\t0.263111\t0.721778\tEpoch: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-fc4c8ee49eb4>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtrain_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mtest_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0madv_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch_adversarial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-d7509797433a>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(loader, model, opt)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtotal_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_err\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\" Regular Training \"\"\"\n",
        "import json\n",
        "from torch.nn import CrossEntropyLoss, Conv2d\n",
        "\n",
        "model_reg = resnet18()\n",
        "\n",
        "# CIFAR10: kernel_size 7 -> 3, stride 2 -> 1, padding 3->1\n",
        "model_reg.conv1 = Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_reg.fc = torch.nn.Linear(model_reg.fc.in_features, num_classes)\n",
        "\n",
        "pretrained_weights = torch.load(weight_file, weights_only=True)\n",
        "model_reg.load_state_dict(pretrained_weights)\n",
        "model_reg = model_reg.to(device)\n",
        "\n",
        "run_dir = project_dir / generate_run_name()\n",
        "run_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "opt = SGD(model_reg.parameters(), lr=1e-1)\n",
        "opt = Adam(model_reg.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 2\n",
        "log = {key: [] for key in [\"train_losses\", \"test_losses\", \"adv_losses\",\n",
        "                           \"train_errors\", \"test_errors\", \"adv_errors\"]}\n",
        "\n",
        "print(f\"Begin adversarial training run: {run_dir.stem}\\n\")\n",
        "print(*(\"TR      \", \"TE      \", \"ADV     \", \"     \"), sep=\"\\t\")\n",
        "\n",
        "for t in range(epochs):\n",
        "    train_err, train_loss = train_epoch(dataloader_train, model_reg, opt)\n",
        "    test_err, test_loss = eval_epoch(dataloader_val, model_reg)\n",
        "    adv_err, adv_loss = eval_epoch_adversarial(dataloader_val, model_reg, fgsm)\n",
        "\n",
        "    # Update the losses and errors\n",
        "    log[\"train_losses\"] += [train_loss]\n",
        "    log[\"test_losses\"] += [test_loss]\n",
        "    log[\"adv_losses\"] += [adv_loss]\n",
        "    log[\"train_errors\"] += [train_err]\n",
        "    log[\"test_errors\"] += [test_err]\n",
        "    log[\"adv_errors\"] += [adv_err]\n",
        "\n",
        "    print(*(\"{:.6f}\".format(train_err),\n",
        "            \"{:.6f}\".format(test_err),\n",
        "            \"{:.6f}\".format(adv_err),\n",
        "            f\"Epoch: {t+1}\",), sep=\"\\t\")\n",
        "\n",
        "with open(run_dir / \"log.json\", \"w\") as f:\n",
        "    json.dump(log, f)\n",
        "torch.save(model_reg.state_dict(), run_dir / \"model_reg.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "sNAZgohWXLfM",
        "outputId": "6671570a-60d0-4b0e-a4e1-198e1430ea58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin adversarial training run: silver-slow-eagle-20250105-1442\n",
            "\n",
            "TR      \tTE      \tADV     \tEpoch   \n",
            "0.705580\t0.452667\t0.527889\t1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3e43d6ab02c7>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TR      \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TE      \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ADV     \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Epoch   \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrain_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch_adversarial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpgd_linf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mtest_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_adv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0madv_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch_adversarial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-d7509797433a>\u001b[0m in \u001b[0;36mtrain_epoch_adversarial\u001b[0;34m(loader, model, attack, opt, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5eb75f2e63a9>\u001b[0m in \u001b[0;36mpgd_linf\u001b[0;34m(model, X, y, epsilon, alpha, num_iter, randomize)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\" Adversarial Training \"\"\"\n",
        "import json\n",
        "from torch.nn import CrossEntropyLoss, Conv2d\n",
        "\n",
        "model_adv = resnet18()\n",
        "\n",
        "# CIFAR10: kernel_size 7 -> 3, stride 2 -> 1, padding 3->1\n",
        "model_adv.conv1 = Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_adv.fc = torch.nn.Linear(model_adv.fc.in_features, num_classes)\n",
        "\n",
        "pretrained_weights = torch.load(weight_file, weights_only=True)\n",
        "model_adv.load_state_dict(pretrained_weights)\n",
        "model_adv = model_adv.to(device)\n",
        "\n",
        "run_dir = project_dir / generate_run_name()\n",
        "run_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# opt = SGD(model_adv.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
        "opt = Adam(model_adv.parameters(), lr=1e-3)\n",
        "# opt = SGD(model_adv.parameters(), lr=1e-1)\n",
        "# opt = SGD(model_adv.parameters(), lr=1e-1, weight_decay=5e-4)\n",
        "\n",
        "# scheduler = CosineAnnealingLR(opt, T_max=100)\n",
        "# scheduler = CosineAnnealingWarmRestarts(opt, T_0=10, T_mult=2, eta_min=0)\n",
        "\n",
        "epochs = 5\n",
        "log = {key: [] for key in [\"train_losses\", \"test_losses\", \"adv_losses\",\n",
        "                           \"train_errors\", \"test_errors\", \"adv_errors\"]}\n",
        "\n",
        "print(f\"Begin adversarial training run: {run_dir.stem}\\n\")\n",
        "print(*(\"TR      \", \"TE      \", \"ADV     \", \"Epoch   \"), sep=\"\\t\")\n",
        "for t in range(epochs):\n",
        "    train_err, train_loss = train_epoch_adversarial(dataloader_train, model_adv, pgd_linf, opt)\n",
        "    test_err, test_loss = eval_epoch(dataloader_val, model_adv)\n",
        "    adv_err, adv_loss = eval_epoch_adversarial(dataloader_val, model_adv, fgsm)\n",
        "\n",
        "    # Update the losses and errors\n",
        "    log[\"train_losses\"] += [train_loss]\n",
        "    log[\"test_losses\"] += [test_loss]\n",
        "    log[\"adv_losses\"] += [adv_loss]\n",
        "    log[\"train_errors\"] += [train_err]\n",
        "    log[\"test_errors\"] += [test_err]\n",
        "    log[\"adv_errors\"] += [adv_err]\n",
        "\n",
        "    print(*(\"{:.6f}\".format(train_err),\n",
        "            \"{:.6f}\".format(test_err),\n",
        "            \"{:.6f}\".format(adv_err),\n",
        "            f\"{t+1}\",), sep=\"\\t\")\n",
        "\n",
        "with open(run_dir / \"log.json\", \"w\") as f:\n",
        "    json.dump(log, f)\n",
        "torch.save(model_adv.state_dict(), run_dir / \"model_adv.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcUht5uBHlYG"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "gold-bright-eagle-20241204-1128:\n",
        "SGD(lr=1e-1), batch_size=1024\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "orange-kind-hawk-20241204-1148:\n",
        "SGD(lr=1e-1, weight_decay=5e-4), batch_size=1024\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "silver-shiny-phoenix-20241204-1210:\n",
        "SGD(lr=1e-1, weight_decay=5e-4, momentum=0.9, nesterov=True), batch_size=1024\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "gray-fierce-octopus-20241204-1226:\n",
        "SGD(lr=1e-1, weight_decay=5e-4, momentum=0.9, nesterov=True), batch_size=1024, CosineAnnealingLR\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "gold-loud-cheetah-20241204-1414:\n",
        "SGD(lr=1e-1, weight_decay=5e-4, momentum=0.9, nesterov=True), batch_size=1024,, epsilon=4/255\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "cyan-wise-eagle-20241203-1710:\n",
        "SGD(lr=1e-1, weight_decay=5e-4, momentum=0.9, nesterov=True), batch_size=1024,, epsilon=32/255\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/fra31/auto-attack"
      ],
      "metadata": {
        "id": "3CJs5EBFu26D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autoattack import AutoAttack\n",
        "\n",
        "X, y = next(iter(dataloader_test))\n",
        "X, y = X.to(device), y.to(device)\n",
        "\n",
        "adversary = AutoAttack(model_adv, norm='Linf', eps=8/255, version='standard')\n",
        "adv_examples = adversary.run_standard_evaluation(X, y, bs=128) # this takes ~8min on T4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uknpMFbi73zO",
        "outputId": "c1c7d7a6-5fc1-4fb7-a49c-c8dd79c84c60"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setting parameters for standard version\n",
            "using standard version including apgd-ce, apgd-t, fab-t, square.\n",
            "initial accuracy: 58.30%\n",
            "apgd-ce - 1/5 - 35 out of 128 successfully perturbed\n",
            "apgd-ce - 2/5 - 29 out of 128 successfully perturbed\n",
            "apgd-ce - 3/5 - 32 out of 128 successfully perturbed\n",
            "apgd-ce - 4/5 - 31 out of 128 successfully perturbed\n",
            "apgd-ce - 5/5 - 23 out of 71 successfully perturbed\n",
            "robust accuracy after APGD-CE: 43.30% (total time 16.5 s)\n",
            "apgd-t - 1/4 - 17 out of 128 successfully perturbed\n",
            "apgd-t - 2/4 - 14 out of 128 successfully perturbed\n",
            "apgd-t - 3/4 - 16 out of 128 successfully perturbed\n",
            "apgd-t - 4/4 - 7 out of 49 successfully perturbed\n",
            "robust accuracy after APGD-T: 37.90% (total time 122.8 s)\n",
            "fab-t - 1/3 - 3 out of 128 successfully perturbed\n",
            "fab-t - 2/3 - 2 out of 128 successfully perturbed\n",
            "fab-t - 3/3 - 2 out of 123 successfully perturbed\n",
            "robust accuracy after FAB-T: 37.20% (total time 285.0 s)\n",
            "square - 1/3 - 1 out of 128 successfully perturbed\n",
            "square - 2/3 - 1 out of 128 successfully perturbed\n",
            "square - 3/3 - 2 out of 116 successfully perturbed\n",
            "robust accuracy after SQUARE: 36.80% (total time 446.3 s)\n",
            "Warning: Square Attack has decreased the robust accuracy of 0.40%. This might indicate that the robustness evaluation using AutoAttack is unreliable. Consider running Square Attack with more iterations and restarts or an adaptive attack. See flags_doc.md for details.\n",
            "max Linf perturbation: 1.98785, nan in tensor: 0, max: 2.13169, min: -1.98785\n",
            "robust accuracy: 36.80%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}